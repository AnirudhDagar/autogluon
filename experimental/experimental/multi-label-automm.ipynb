{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006021b7-7d11-4356-97fc-f241694eab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.core.utils.loaders import load_zip\n",
    "import os\n",
    "\n",
    "download_dir = './ag_multimodal_tutorial'\n",
    "zip_file = 'https://automl-mm-bench.s3.amazonaws.com/petfinder_for_tutorial.zip'\n",
    "\n",
    "load_zip.unzip(zip_file, unzip_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2295a6fe-1b2d-4051-8ab7-a1b32772d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = f'{download_dir}/petfinder_for_tutorial'\n",
    "\n",
    "def invert_label(val):\n",
    "    if val==1:\n",
    "        return 0\n",
    "    elif val==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "train_data = pd.read_csv(f'{dataset_path}/train.csv', index_col=0)\n",
    "# train_data['AdoptionSpeed_Inv'] = train_data['AdoptionSpeed'].apply(invert_label)\n",
    "# train_data['final_label'] = train_data.apply(lambda row: [row['AdoptionSpeed'], row['AdoptionSpeed_Inv']], axis=1)\n",
    "# train_data = train_data.drop(columns=['AdoptionSpeed_Inv', 'AdoptionSpeed'])\n",
    "\n",
    "test_data = pd.read_csv(f'{dataset_path}/test.csv', index_col=0)\n",
    "# test_data['AdoptionSpeed_Inv'] = test_data['AdoptionSpeed'].apply(invert_label)\n",
    "# test_data['final_label'] = test_data.apply(lambda row: [row['AdoptionSpeed'], row['AdoptionSpeed_Inv']], axis=1)\n",
    "# test_data = test_data.drop(columns=['AdoptionSpeed_Inv', 'AdoptionSpeed'])\n",
    "\n",
    "# label_col = ['AdoptionSpeed', 'AdoptionSpeed_Inv']\n",
    "label_col = 'AdoptionSpeed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7489e35e-bab7-490e-b30b-901c1f90cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_col = 'Images'\n",
    "\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele: ele.split(';')[0])\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele: ele.split(';')[0])\n",
    "\n",
    "def path_expander(path, base_folder):\n",
    "    path_l = path.split(';')\n",
    "    return ';'.join([os.path.abspath(os.path.join(base_folder, path)) for path in path_l])\n",
    "\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele: path_expander(ele, base_folder=dataset_path))\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele: path_expander(ele, base_folder=dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5490181c-5214-42e5-80df-322654f26ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I rescued Yumi Hamasaki at a food stall far away in Kelantan. At that time i was on my way back to KL, she was suffer from stomach problem and looking very2 sick.. I send her to vet & get the treatment + vaccinated and right now she's very2 healthy.. About yumi : - love to sleep with ppl - she will keep on meowing if she's hugry - very2 active, always seeking for people to accompany her playing - well trained (poo+pee in her own potty) - easy to bathing - I only feed her with these brands : IAMS, Kittenbites, Pro-formance Reason why i need someone to adopt Yumi: I just married and need to move to a new house where no pets are allowed :( As Yumi is very2 special to me, i will only give her to ppl that i think could take care of her just like i did (especially on her foods things)..\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_row = train_data.iloc[0]\n",
    "example_image = example_row[image_col]\n",
    "\n",
    "from IPython.display import Image, display\n",
    "pil_img = Image(filename=example_image)\n",
    "display(pil_img)\n",
    "\n",
    "example_row['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ee14a1-d78a-4eeb-9374-94a5c05d29e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Yumi Hamasaki</td>\n",
       "      <td>4</td>\n",
       "      <td>292</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>bcc4e1b9557a8b3aaf545ea8e6e86991</td>\n",
       "      <td>0</td>\n",
       "      <td>I rescued Yumi Hamasaki at a food stall far aw...</td>\n",
       "      <td>7d7a39d71</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/anidagar/Desktop/Work/autogluon/experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nene/ Kimie</td>\n",
       "      <td>12</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>f0450bf0efe0fa3ff9321d0b827b1237</td>\n",
       "      <td>0</td>\n",
       "      <td>Has adopted by a friend with new pet name Kimie</td>\n",
       "      <td>0e107c82f</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/anidagar/Desktop/Work/autogluon/experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mattie</td>\n",
       "      <td>12</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>9b52af6d48a4521fd01d4028eb5879a3</td>\n",
       "      <td>0</td>\n",
       "      <td>I rescued Mattie with a broken leg. After surg...</td>\n",
       "      <td>1a8fd6707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/anidagar/Desktop/Work/autogluon/experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>307</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>88da1210e021a5cf43480b074778f3bc</td>\n",
       "      <td>0</td>\n",
       "      <td>She born on 30 September . I really hope the a...</td>\n",
       "      <td>bca8b44ae</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/anidagar/Desktop/Work/autogluon/experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Coco</td>\n",
       "      <td>6</td>\n",
       "      <td>276</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>41326</td>\n",
       "      <td>227d7b1bcfaffb5f9882bf57b5ee8fab</td>\n",
       "      <td>0</td>\n",
       "      <td>Calico Tame and easy going Diet RC Kitten Supp...</td>\n",
       "      <td>2def67952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>/Users/anidagar/Desktop/Work/autogluon/experim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type           Name  Age  Breed1  Breed2  Gender  Color1  Color2  Color3  \\\n",
       "0     2  Yumi Hamasaki    4     292     265       2       1       5       7   \n",
       "1     2    Nene/ Kimie   12     285       0       2       5       6       7   \n",
       "2     2         Mattie   12     266       0       2       1       7       0   \n",
       "3     1            NaN    1     189     307       2       1       2       0   \n",
       "4     2           Coco    6     276     285       2       2       4       7   \n",
       "\n",
       "   MaturitySize  ...  Quantity  Fee  State                         RescuerID  \\\n",
       "0             2  ...         1    0  41326  bcc4e1b9557a8b3aaf545ea8e6e86991   \n",
       "1             2  ...         1    0  41326  f0450bf0efe0fa3ff9321d0b827b1237   \n",
       "2             2  ...         1    0  41401  9b52af6d48a4521fd01d4028eb5879a3   \n",
       "3             2  ...         1    0  41401  88da1210e021a5cf43480b074778f3bc   \n",
       "4             2  ...         1  100  41326  227d7b1bcfaffb5f9882bf57b5ee8fab   \n",
       "\n",
       "   VideoAmt                                        Description      PetID  \\\n",
       "0         0  I rescued Yumi Hamasaki at a food stall far aw...  7d7a39d71   \n",
       "1         0    Has adopted by a friend with new pet name Kimie  0e107c82f   \n",
       "2         0  I rescued Mattie with a broken leg. After surg...  1a8fd6707   \n",
       "3         0  She born on 30 September . I really hope the a...  bca8b44ae   \n",
       "4         0  Calico Tame and easy going Diet RC Kitten Supp...  2def67952   \n",
       "\n",
       "   PhotoAmt AdoptionSpeed                                             Images  \n",
       "0       3.0             0  /Users/anidagar/Desktop/Work/autogluon/experim...  \n",
       "1       3.0             0  /Users/anidagar/Desktop/Work/autogluon/experim...  \n",
       "2       5.0             0  /Users/anidagar/Desktop/Work/autogluon/experim...  \n",
       "3       3.0             0  /Users/anidagar/Desktop/Work/autogluon/experim...  \n",
       "4       1.0             0  /Users/anidagar/Desktop/Work/autogluon/experim...  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a513e7d3-cf8f-431a-8b20-2028b1798f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231025_000756\"\n",
      "/Users/anidagar/Desktop/Work/autogluon/core/src/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "INFO: Global seed set to 0\n",
      "AutoMM starts to create your model. ✨\n",
      "\n",
      "- AutoGluon version is 0.8.3b20231003.\n",
      "\n",
      "- Pytorch version is 2.0.1.\n",
      "\n",
      "- Model will be saved to \"/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756\".\n",
      "\n",
      "- Validation metric is \"roc_auc\".\n",
      "\n",
      "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756\n",
      "    ```\n",
      "\n",
      "Enjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n",
      "\n",
      "/Users/anidagar/miniconda3/envs/autogluon/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "0 GPUs are detected, and 0 GPUs will be used.\n",
      "\n",
      "/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 198 M \n",
      "1 | validation_metric | BinaryAUROC         | 0     \n",
      "2 | loss_func         | CrossEntropyLoss    | 0     \n",
      "----------------------------------------------------------\n",
      "198 M     Trainable params\n",
      "0         Non-trainable params\n",
      "198 M     Total params\n",
      "792.034   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anidagar/miniconda3/envs/autogluon/lib/python3.10/site-packages/timm/models/swin_transformer.py:292: UserWarning: The operator 'aten::roll' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  shifted_x = torch.roll(x, shifts=(-self.shift_size[0], -self.shift_size[1]), dims=(1, 2))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd091886d8749e499c54f7bad7addd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 1: 'val_roc_auc' reached 0.40056 (best 0.40056), saving model to '/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756/epoch=0-step=1.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 4: 'val_roc_auc' reached 0.40056 (best 0.40056), saving model to '/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756/epoch=0-step=4.ckpt' as top 3\n",
      "INFO: Time limit reached. Elapsed time is 0:02:01. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start to fuse 2 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c535771cd091433984e6053cdd8a5ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730ddb2a418a46858f4755be58cdced8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model 🎉🎉🎉\n",
      "\n",
      "- To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756\")\n",
      "    ```\n",
      "\n",
      "- You can open a terminal and launch Tensorboard to visualize the training log:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000756\n",
      "    ```\n",
      "\n",
      "- If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub: https://github.com/autogluon/autogluon\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "predictor = MultiModalPredictor(label=label_col, problem_type='classification').fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb3bd0-08ae-4d02-bd54-4a9067f83e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231025_000257\"\n",
      "/Users/anidagar/Desktop/Work/autogluon/core/src/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "INFO: Global seed set to 0\n",
      "AutoMM starts to create your model. ✨\n",
      "\n",
      "- AutoGluon version is 0.8.3b20231003.\n",
      "\n",
      "- Pytorch version is 2.0.1.\n",
      "\n",
      "- Model will be saved to \"/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000257\".\n",
      "\n",
      "- Validation metric is \"roc_auc\".\n",
      "\n",
      "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231025_000257\n",
      "    ```\n",
      "\n",
      "Enjoy your coffee, and let AutoMM do the job ☕☕☕ Learn more at https://auto.gluon.ai\n",
      "\n",
      "/Users/anidagar/miniconda3/envs/autogluon/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "0 GPUs are detected, and 0 GPUs will be used.\n",
      "\n",
      "/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/utils/environment.py:91: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | model             | MultimodalFusionMLP | 198 M \n",
      "1 | validation_metric | BinaryAUROC         | 0     \n",
      "2 | loss_func         | CrossEntropyLoss    | 0     \n",
      "----------------------------------------------------------\n",
      "198 M     Trainable params\n",
      "0         Non-trainable params\n",
      "198 M     Total params\n",
      "792.034   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image_image': tensor([[[[[ 0.7762,  0.8104,  0.7933,  ...,  0.8276,  0.8104,  0.7762],\n",
      "           [ 0.8276,  0.7933,  0.7419,  ...,  0.8104,  0.7762,  0.7933],\n",
      "           [ 0.7762,  0.7248,  0.6734,  ...,  0.8104,  0.7591,  0.7933],\n",
      "           ...,\n",
      "           [ 0.7762,  1.5297,  2.0605,  ...,  0.3138,  0.2453,  0.2624],\n",
      "           [ 1.2043,  1.2899,  1.9407,  ...,  0.2967,  0.1768,  0.2282],\n",
      "           [ 1.5297,  1.3413,  1.5810,  ...,  0.2453,  0.1939,  0.2282]],\n",
      "\n",
      "          [[ 0.0301,  0.0651,  0.0476,  ...,  0.8704,  0.8529,  0.8179],\n",
      "           [ 0.0826,  0.0476, -0.0049,  ...,  0.8529,  0.8179,  0.8354],\n",
      "           [ 0.0301, -0.0224, -0.0749,  ...,  0.8529,  0.8004,  0.8354],\n",
      "           ...,\n",
      "           [ 0.4503,  1.2031,  1.6758,  ...,  0.4153,  0.3452,  0.3627],\n",
      "           [ 0.7829,  0.8880,  1.5532,  ...,  0.3978,  0.2752,  0.3277],\n",
      "           [ 1.0105,  0.8880,  1.1331,  ...,  0.3452,  0.2927,  0.3102]],\n",
      "\n",
      "          [[-0.2184, -0.1835, -0.2010,  ...,  0.4962,  0.4788,  0.4614],\n",
      "           [-0.2010, -0.2358, -0.2532,  ...,  0.4788,  0.4439,  0.4439],\n",
      "           [-0.2532, -0.3055, -0.3230,  ...,  0.4788,  0.4265,  0.4614],\n",
      "           ...,\n",
      "           [-0.3927,  0.4091,  0.9668,  ...,  0.3742,  0.3219,  0.3742],\n",
      "           [ 0.1476,  0.2696,  0.9668,  ...,  0.3568,  0.2348,  0.3393],\n",
      "           [ 0.6356,  0.4788,  0.7751,  ...,  0.3045,  0.2522,  0.2871]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.3712, -0.3541, -0.3541,  ..., -0.5082, -0.6109,  0.5364],\n",
      "           [-0.4397, -0.4054, -0.4054,  ..., -0.7479, -0.9534, -0.4911],\n",
      "           [-0.4568, -0.4911, -0.5082,  ..., -0.9020, -1.0904, -1.2274],\n",
      "           ...,\n",
      "           [-1.0562, -1.0390, -1.0390,  ..., -1.5699, -1.5357, -1.5185],\n",
      "           [-1.0390, -1.0562, -1.0733,  ..., -1.5870, -1.5699, -1.5528],\n",
      "           [-1.0562, -1.1075, -1.1418,  ..., -1.6042, -1.5870, -1.5528]],\n",
      "\n",
      "          [[ 0.0476,  0.0651,  0.0476,  ..., -0.6702, -0.7052,  0.5378],\n",
      "           [-0.0049,  0.0301, -0.0049,  ..., -0.7927, -0.9153, -0.4076],\n",
      "           [-0.0749, -0.0574, -0.0399,  ..., -0.8627, -1.0028, -1.1253],\n",
      "           ...,\n",
      "           [-1.0378, -1.0203, -1.0203,  ..., -1.5805, -1.5455, -1.5280],\n",
      "           [-1.0203, -1.0378, -1.0553,  ..., -1.5630, -1.5455, -1.5105],\n",
      "           [-1.0378, -1.0903, -1.1253,  ..., -1.5805, -1.5630, -1.5280]],\n",
      "\n",
      "          [[ 0.3219,  0.4265,  0.5311,  ..., -0.5147, -0.5147,  0.7576],\n",
      "           [ 0.2696,  0.3568,  0.4788,  ..., -0.6890, -0.8110, -0.3055],\n",
      "           [ 0.2696,  0.3568,  0.4439,  ..., -0.7761, -0.8981, -1.0201],\n",
      "           ...,\n",
      "           [-0.8981, -0.8807, -0.8633,  ..., -1.5256, -1.5081, -1.4733],\n",
      "           [-0.8981, -0.9330, -0.9504,  ..., -1.5256, -1.5081, -1.4907],\n",
      "           [-0.9156, -0.9504, -0.9853,  ..., -1.5430, -1.5256, -1.4907]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.5125,  1.2899,  0.5536,  ...,  0.9474,  0.9646,  0.9303],\n",
      "           [ 1.5297,  1.3755,  0.8276,  ...,  0.9988,  1.0159,  0.9817],\n",
      "           [ 1.5125,  1.4098,  1.0502,  ...,  1.0331,  1.0673,  1.0673],\n",
      "           ...,\n",
      "           [-0.0458, -0.0972, -0.1657,  ...,  0.4679,  0.5364,  0.5022],\n",
      "           [-0.3883, -0.2342, -0.2684,  ...,  0.3652,  0.4508,  0.6049],\n",
      "           [-0.2856, -0.1999, -0.3027,  ...,  0.4679,  0.3309,  0.4337]],\n",
      "\n",
      "          [[ 1.8859,  1.7108,  0.9930,  ...,  0.9055,  0.8704,  0.8529],\n",
      "           [ 1.9559,  1.8158,  1.2731,  ...,  0.9755,  0.9405,  0.9055],\n",
      "           [ 1.9734,  1.9034,  1.5532,  ...,  1.0630,  1.0280,  0.9930],\n",
      "           ...,\n",
      "           [-0.3550, -0.3550, -0.3901,  ...,  0.2052,  0.2752,  0.2402],\n",
      "           [-0.7052, -0.4951, -0.5126,  ...,  0.0476,  0.1877,  0.3627],\n",
      "           [-0.5826, -0.4776, -0.5651,  ...,  0.1527,  0.0826,  0.2227]],\n",
      "\n",
      "          [[ 2.4483,  2.2914,  1.5768,  ...,  0.8274,  0.8448,  0.7751],\n",
      "           [ 2.5006,  2.3960,  1.8383,  ...,  0.8797,  0.8971,  0.8274],\n",
      "           [ 2.5006,  2.4134,  2.0823,  ...,  0.9668,  0.9842,  0.9145],\n",
      "           ...,\n",
      "           [-0.0615, -0.0964, -0.1487,  ...,  0.5659,  0.6356,  0.6008],\n",
      "           [-0.4101, -0.2358, -0.2707,  ...,  0.4265,  0.5485,  0.7228],\n",
      "           [-0.3055, -0.2184, -0.3055,  ...,  0.5311,  0.4439,  0.5485]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980],\n",
      "           [-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980],\n",
      "           [-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980],\n",
      "           ...,\n",
      "           [-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980],\n",
      "           [-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980],\n",
      "           [-1.6555, -2.0152, -1.9638,  ..., -1.9980, -1.9980, -1.9980]],\n",
      "\n",
      "          [[-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957],\n",
      "           [-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957],\n",
      "           [-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957],\n",
      "           ...,\n",
      "           [-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957],\n",
      "           [-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957],\n",
      "           [-1.5630, -1.9307, -1.8782,  ..., -1.8957, -1.8957, -1.8957]],\n",
      "\n",
      "          [[-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302],\n",
      "           [-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302],\n",
      "           [-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302],\n",
      "           ...,\n",
      "           [-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302],\n",
      "           [-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302],\n",
      "           [-1.2990, -1.6650, -1.6127,  ..., -1.6302, -1.6302, -1.6302]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 0.2111,  0.0569,  0.5536,  ..., -0.1314,  0.2796,  0.3823],\n",
      "           [-0.5596, -0.2171,  0.1939,  ...,  0.0227,  0.4166,  0.4679],\n",
      "           [-0.5767, -0.4054, -0.0801,  ...,  0.1939,  0.4851,  0.4679],\n",
      "           ...,\n",
      "           [-1.0048, -1.2274, -0.7479,  ..., -0.5596, -0.5596, -0.5424],\n",
      "           [-1.0390, -1.1760, -0.6965,  ..., -0.6794, -0.7993, -0.9877],\n",
      "           [-1.1247, -1.2617, -0.9192,  ..., -1.4843, -1.5870, -1.7412]],\n",
      "\n",
      "          [[ 0.3803,  0.2577,  0.7654,  ...,  0.1001,  0.5378,  0.6254],\n",
      "           [-0.4251, -0.0574,  0.3978,  ...,  0.1877,  0.5903,  0.6604],\n",
      "           [-0.4251, -0.2500,  0.1001,  ...,  0.3102,  0.6078,  0.5903],\n",
      "           ...,\n",
      "           [-0.7752, -1.0728, -0.6527,  ..., -0.4251, -0.4076, -0.3725],\n",
      "           [-0.7752, -1.0553, -0.6702,  ..., -0.5301, -0.6352, -0.8277],\n",
      "           [-0.8452, -1.1604, -0.9328,  ..., -1.3529, -1.4405, -1.5980]],\n",
      "\n",
      "          [[ 0.1128,  0.0256,  0.6008,  ...,  0.0779,  0.4962,  0.5485],\n",
      "           [-0.6367, -0.2358,  0.2348,  ...,  0.1302,  0.5136,  0.5485],\n",
      "           [-0.5670, -0.3927, -0.0441,  ...,  0.2173,  0.4962,  0.4439],\n",
      "           ...,\n",
      "           [-0.8633, -1.1770, -0.7587,  ..., -0.3753, -0.4101, -0.4624],\n",
      "           [-0.8981, -1.1596, -0.7761,  ..., -0.5321, -0.6890, -0.9330],\n",
      "           [-0.9853, -1.2641, -1.0201,  ..., -1.3861, -1.5081, -1.7173]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-0.3883, -0.3541, -0.3883,  ..., -1.2617, -1.2788, -1.3130],\n",
      "           [-0.3712, -0.3369, -0.4054,  ..., -1.6898, -1.6727, -1.6898],\n",
      "           [-0.3883, -0.3027, -0.3541,  ..., -1.5870, -1.7069, -1.6555],\n",
      "           ...,\n",
      "           [-0.9534, -0.9020, -0.9192,  ..., -0.6965, -0.5424, -0.7479],\n",
      "           [-0.9363, -0.8507, -0.9363,  ..., -0.9877, -0.9705, -0.8849],\n",
      "           [-0.8678, -0.8849, -0.9534,  ..., -0.8678, -0.6109, -0.8678]],\n",
      "\n",
      "          [[-0.3200, -0.2675, -0.3725,  ..., -0.9503, -1.0378, -1.1078],\n",
      "           [-0.3200, -0.2675, -0.3725,  ..., -1.3529, -1.3880, -1.3880],\n",
      "           [-0.4076, -0.2850, -0.3200,  ..., -1.2129, -1.3179, -1.2304],\n",
      "           ...,\n",
      "           [-0.8803, -0.8277, -0.8452,  ..., -0.4776, -0.2675, -0.4601],\n",
      "           [-0.8627, -0.7752, -0.8452,  ..., -0.7927, -0.7927, -0.7052],\n",
      "           [-0.8102, -0.7927, -0.8627,  ..., -0.6702, -0.4951, -0.7752]],\n",
      "\n",
      "          [[-0.6715, -0.6541, -0.6890,  ..., -1.1073, -1.1944, -1.2641],\n",
      "           [-0.6715, -0.6541, -0.7064,  ..., -1.5779, -1.6127, -1.6302],\n",
      "           [-0.7413, -0.6715, -0.6715,  ..., -1.5604, -1.6824, -1.5953],\n",
      "           ...,\n",
      "           [-0.8981, -0.8110, -0.8458,  ..., -0.3753, -0.2184, -0.4275],\n",
      "           [-0.8458, -0.8458, -0.8981,  ..., -0.6367, -0.6367, -0.5670],\n",
      "           [-0.7761, -0.8981, -0.9678,  ..., -0.5147, -0.3055, -0.5670]]]]],\n",
      "       device='mps:0'), 'timm_image_image_valid_num': tensor([1, 1, 1, 1, 1, 1, 1, 1], device='mps:0'), 'hf_text_text_token_ids': tensor([[ 101, 1016,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 1016,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 1015,  102,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1015,  102,  ...,    0,    0,    0],\n",
      "        [ 101, 1016,  102,  ...,  102, 1014,  102],\n",
      "        [ 101, 1015,  102,  ...,    0,    0,    0]], device='mps:0',\n",
      "       dtype=torch.int32), 'hf_text_text_valid_length': tensor([165, 254,  75, 137, 148, 150, 322, 124], device='mps:0'), 'hf_text_text_segment_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 1],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='mps:0', dtype=torch.int32), 'hf_text_choices_ids': tensor([], device='mps:0', size=(8, 0), dtype=torch.int32), 'numerical_mlp_numerical': tensor([[-0.5891,  0.7584, -0.6786, -0.3065,  0.4753],\n",
      "        [-0.4821, -0.1518, -0.6786, -0.3065,  0.1499],\n",
      "        [-0.6426,  0.7584,  1.7305, -0.3065, -0.8266],\n",
      "        [-0.5356,  0.6260, -0.6786, -0.3065,  0.4753],\n",
      "        [-0.2146, -0.1187, -0.6786, -0.3065,  0.4753],\n",
      "        [ 3.7436, -1.1944, -0.6786,  3.4859, -0.1756],\n",
      "        [-0.4821,  0.0799, -0.6786, -0.3065,  0.1499],\n",
      "        [-0.5356,  0.0799, -0.6786, -0.3065, -0.1756]], device='mps:0'), 'fusion_mlp_label': tensor([0, 1, 0, 0, 1, 0, 0, 0], device='mps:0'), 'hf_text_label': tensor([0, 1, 0, 0, 1, 0, 0, 0], device='mps:0'), 'numerical_mlp_label': tensor([0, 1, 0, 0, 1, 0, 0, 0], device='mps:0'), 'timm_image_label': tensor([0, 1, 0, 0, 1, 0, 0, 0], device='mps:0')}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m    216 \u001b[0m        \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    217 \u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    218 \u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_off_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    219 \u001b[0m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    220 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    222 \u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    223 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    224 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    225 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    226 \u001b[0m        \"\"\"\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultimodalFusionMLP(\n",
      "  (model): ModuleList(\n",
      "    (0): HFAutoModelForTextPrediction(\n",
      "      (model): ElectraModel(\n",
      "        (embeddings): ElectraEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): ElectraEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0-11): 12 x ElectraLayer(\n",
      "              (attention): ElectraAttention(\n",
      "                (self): ElectraSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): ElectraSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): ElectraIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (intermediate_act_fn): GELUActivation()\n",
      "              )\n",
      "              (output): ElectraOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "    (1): NumericalMLP(\n",
      "      (numerical_feature_tokenizer): Identity()\n",
      "      (mlp): MLP(\n",
      "        (layers): Sequential(\n",
      "          (0): Unit(\n",
      "            (norm): LayerNorm((5,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc): Linear(in_features=5, out_features=128, bias=True)\n",
      "            (act_fn): LeakyReLU(negative_slope=0.01)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (head): Linear(in_features=128, out_features=2, bias=True)\n",
      "    )\n",
      "    (2): TimmAutoModelForImagePrediction(\n",
      "      (model): SwinTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (layers): Sequential(\n",
      "          (0): SwinTransformerStage(\n",
      "            (downsample): Identity()\n",
      "            (blocks): Sequential(\n",
      "              (0): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): Identity()\n",
      "                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): Identity()\n",
      "              )\n",
      "              (1): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.004)\n",
      "                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.004)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): SwinTransformerStage(\n",
      "            (downsample): PatchMerging(\n",
      "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "              (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "            (blocks): Sequential(\n",
      "              (0): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.009)\n",
      "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.009)\n",
      "              )\n",
      "              (1): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.013)\n",
      "                (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.013)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): SwinTransformerStage(\n",
      "            (downsample): PatchMerging(\n",
      "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
      "            )\n",
      "            (blocks): Sequential(\n",
      "              (0): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.017)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.017)\n",
      "              )\n",
      "              (1): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.022)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.022)\n",
      "              )\n",
      "              (2): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.026)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.026)\n",
      "              )\n",
      "              (3): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.030)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.030)\n",
      "              )\n",
      "              (4): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.035)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.035)\n",
      "              )\n",
      "              (5): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.039)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.039)\n",
      "              )\n",
      "              (6): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.043)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.043)\n",
      "              )\n",
      "              (7): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.048)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.048)\n",
      "              )\n",
      "              (8): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.052)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.052)\n",
      "              )\n",
      "              (9): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.057)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.057)\n",
      "              )\n",
      "              (10): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.061)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.061)\n",
      "              )\n",
      "              (11): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.065)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.065)\n",
      "              )\n",
      "              (12): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.070)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.070)\n",
      "              )\n",
      "              (13): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.074)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.074)\n",
      "              )\n",
      "              (14): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.078)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.078)\n",
      "              )\n",
      "              (15): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.083)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.083)\n",
      "              )\n",
      "              (16): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.087)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.087)\n",
      "              )\n",
      "              (17): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.091)\n",
      "                (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.091)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (3): SwinTransformerStage(\n",
      "            (downsample): PatchMerging(\n",
      "              (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "              (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "            )\n",
      "            (blocks): Sequential(\n",
      "              (0): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.096)\n",
      "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.096)\n",
      "              )\n",
      "              (1): SwinTransformerBlock(\n",
      "                (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (attn): WindowAttention(\n",
      "                  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "                  (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                  (softmax): Softmax(dim=-1)\n",
      "                )\n",
      "                (drop_path1): DropPath(drop_prob=0.100)\n",
      "                (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (mlp): Mlp(\n",
      "                  (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "                  (act): GELU(approximate='none')\n",
      "                  (drop1): Dropout(p=0.0, inplace=False)\n",
      "                  (norm): Identity()\n",
      "                  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                  (drop2): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (drop_path2): DropPath(drop_prob=0.100)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (head): ClassifierHead(\n",
      "          (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Identity())\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "          (fc): Identity()\n",
      "          (flatten): Identity()\n",
      "        )\n",
      "      )\n",
      "      (head): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (adapter): ModuleList(\n",
      "    (0): Linear(in_features=768, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1024, bias=True)\n",
      "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (fusion_mlp): Sequential(\n",
      "    (0): MLP(\n",
      "      (layers): Sequential(\n",
      "        (0): Unit(\n",
      "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc): Linear(in_features=3072, out_features=128, bias=True)\n",
      "          (act_fn): LeakyReLU(negative_slope=0.01)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m    227 \u001b[0m        \u001b[0mPer\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mregistered\u001b[0m \u001b[0mby\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    228 \u001b[0m        \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mai\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mstable\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;31m#training-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    229 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    230 \u001b[0m        \u001b[0mParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    231 \u001b[0m        \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    232 \u001b[0m        \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    233 \u001b[0m            \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmini\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincluding\u001b[0m \u001b[0mboth\u001b[0m \u001b[0minput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    234 \u001b[0m            \u001b[0mground\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtruth\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mmini\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0meach\u001b[0m \u001b[0mindividual\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    235 \u001b[0m            \u001b[0mwhich\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0mits\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0minput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mby\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mits\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    236 \u001b[0m            \u001b[0mground\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtruth\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0mare\u001b[0m \u001b[0mused\u001b[0m \u001b[0mhere\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompute\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    237 \u001b[0m        \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anidagar/miniconda3/envs/autogluon/lib/python3.10/site-packages/timm/models/swin_transformer.py:292: UserWarning: The operator 'aten::roll' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  shifted_x = torch.roll(x, shifts=(-self.shift_size[0], -self.shift_size[1]), dims=(1, 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(222)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image': {'weight': tensor(0.1000), 'logits': tensor([[inf, inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [-inf, inf]], device='mps:0')}, 'fusion_mlp': {'logits': tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], device='mps:0'), 'features': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0'), 'weight': tensor(1., device='mps:0')}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m    217 \u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    218 \u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_off_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    219 \u001b[0m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    220 \u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    221 \u001b[0m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    223 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    224 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    225 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    226 \u001b[0m        \"\"\"\n",
      "\u001b[1;32m    227 \u001b[0m        \u001b[0mPer\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mregistered\u001b[0m \u001b[0mby\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 1, 0, 0, 0], device='mps:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self._compute_loss(output=output, label=label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='mps:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(222)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image': {'weight': tensor(0.1000), 'logits': tensor([[-inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [inf, inf],\n",
      "        [-inf, inf],\n",
      "        [inf, inf]], device='mps:0')}, 'fusion_mlp': {'logits': tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], device='mps:0'), 'features': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0'), 'weight': tensor(1., device='mps:0')}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(223)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    225 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan, device='mps:0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f1468253aa41c8a3369d0aa7e1f158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'loss' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(222)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image': {'weight': tensor(0.1000), 'logits': tensor([[inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [inf, -inf],\n",
      "        [inf, inf],\n",
      "        [inf, inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, inf]], device='mps:0', grad_fn=<DivBackward0>)}, 'fusion_mlp': {'logits': tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], device='mps:0', grad_fn=<LinearBackward0>), 'features': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0',\n",
      "       grad_fn=<MulBackward0>), 'weight': tensor(1., device='mps:0')}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  loss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'loss' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(222)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image': {'weight': tensor(0.1000), 'logits': tensor([[inf, inf],\n",
      "        [-inf, inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, inf],\n",
      "        [-inf, inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, inf]], device='mps:0', grad_fn=<DivBackward0>)}, 'fusion_mlp': {'logits': tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], device='mps:0', grad_fn=<LinearBackward0>), 'features': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0',\n",
      "       grad_fn=<MulBackward0>), 'weight': tensor(1., device='mps:0')}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(221)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    219 \u001b[0;31m            \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultimodel_mixup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixup_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixup_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'output' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/anidagar/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/optimization/lit_module.py\u001b[0m(222)\u001b[0;36m_shared_step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    220 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    221 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 222 \u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    223 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    224 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timm_image': {'weight': tensor(0.1000), 'logits': tensor([[-inf, -inf],\n",
      "        [-inf, -inf],\n",
      "        [-inf, inf],\n",
      "        [inf, -inf],\n",
      "        [-inf, inf],\n",
      "        [inf, inf],\n",
      "        [inf, -inf],\n",
      "        [-inf, -inf]], device='mps:0', grad_fn=<DivBackward0>)}, 'fusion_mlp': {'logits': tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], device='mps:0', grad_fn=<LinearBackward0>), 'features': tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='mps:0',\n",
      "       grad_fn=<MulBackward0>), 'weight': tensor(1., device='mps:0')}}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "\n",
    "predictor = MultiModalPredictor(label=label_col, problem_type='classification').fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f8171-5260-41e4-8fd7-ab4e1c9fa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "predictor = MultiModalPredictor.load(\"/Users/anidagar/Desktop/Work/autogluon/experimental/experimental/AutogluonModels/ag-20231022_224902\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff52b6-fe26-4778-8547-130fd4813f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_data.drop(columns=label_col))\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9f82e8-53e7-464a-8ad4-eb2252a9530f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646522aa7aea4c1083aafbe72215ac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "8   0.5  0.5\n",
       "70  0.5  0.5\n",
       "82  0.5  0.5\n",
       "28  0.5  0.5\n",
       "63  0.5  0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = predictor.predict_proba(test_data.drop(columns=label_col))\n",
    "probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621e928d-e35c-401e-8d40-41d91404e453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55db277feff145cdafd1914391841a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'roc_auc': 0.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = predictor.evaluate(test_data, metrics=[\"roc_auc\"])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca90563-5503-4920-912f-242d7e7c7dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AdoptionSpeed'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4096c4b-963f-4427-84c4-0288c2deb716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AdoptionSpeed', 'PhotoAmt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_col = ['AdoptionSpeed', 'PhotoAmt']\n",
    "multilabel_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a433527a-4cdc-4f8f-8d89-d4305192435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_multi_label = True if isinstance(multilabel_col, list) and len(label_col)>1 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06dab473-81fe-4973-80c6-0e3a05be6bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_multi_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f12adfd-8d8a-4e1a-9953-8188858f1830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(multilabel_col, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fa0ffd-6503-4474-9e36-dc157b785e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6755db2d-aaed-493d-95df-0f1818a5fc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f639ea94-9409-48c2-910b-ecf3e3c306fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv | Columns = 15 / 15 | Rows = 39073 -> 39073\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt      education  education-num  \\\n",
       "6118    51   Private   39264   Some-college             10   \n",
       "23204   58   Private   51662           10th              6   \n",
       "29590   40   Private  326310   Some-college             10   \n",
       "18116   37   Private  222450        HS-grad              9   \n",
       "33964   62   Private  109190      Bachelors             13   \n",
       "\n",
       "            marital-status        occupation    relationship    race      sex  \\\n",
       "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
       "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
       "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
       "18116        Never-married             Sales   Not-in-family   White     Male   \n",
       "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
       "6118              0             0              40   United-States    >50K  \n",
       "23204             0             0               8   United-States   <=50K  \n",
       "29590             0             0              44   United-States   <=50K  \n",
       "18116             0          2339              40     El-Salvador   <=50K  \n",
       "33964         15024             0              40   United-States    >50K  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbcaaea1-66a9-41ca-bd61-e25da1ac5b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231004_033607\"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Provided DataFrame does not contain label column: ['education-num', 'education', 'class']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mMultiModalPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/predictor.py:754\u001b[0m, in \u001b[0;36mMultiModalPredictor.fit\u001b[0;34m(self, train_data, presets, config, tuning_data, max_num_tuning_data, id_mappings, time_limit, save_path, hyperparameters, column_types, holdout_frac, teacher_predictor, seed, standalone, hyperparameter_tune_kwargs, clean_ckpts)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_path \u001b[38;5;241m=\u001b[39m setup_save_path(\n\u001b[1;32m    745\u001b[0m     resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resume,\n\u001b[1;32m    746\u001b[0m     old_save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    750\u001b[0m     fit_called\u001b[38;5;241m=\u001b[39mfit_called,\n\u001b[1;32m    751\u001b[0m )\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tuning_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 754\u001b[0m     train_data, tuning_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_train_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_column:\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_problem_type \u001b[38;5;241m=\u001b[39m infer_problem_type(\n\u001b[1;32m    760\u001b[0m         y_train_data\u001b[38;5;241m=\u001b[39mtrain_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_column],\n\u001b[1;32m    761\u001b[0m         provided_problem_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_problem_type,\n\u001b[1;32m    762\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Work/autogluon/multimodal/src/autogluon/multimodal/predictor.py:932\u001b[0m, in \u001b[0;36mMultiModalPredictor._split_train_tuning\u001b[0;34m(self, data, holdout_frac, random_state)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m     problem_type_for_split \u001b[38;5;241m=\u001b[39m REGRESSION\n\u001b[0;32m--> 932\u001b[0m train_data, tuning_data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_train_test_split_combined\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_frac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproblem_type_for_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_data, tuning_data\n",
      "File \u001b[0;32m~/Desktop/Work/autogluon/core/src/autogluon/core/utils/utils.py:393\u001b[0m, in \u001b[0;36mgenerate_train_test_split_combined\u001b[0;34m(data, label, problem_type, test_size, random_state, min_cls_count_train)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_train_test_split_combined\u001b[39m(\n\u001b[1;32m    362\u001b[0m     data: DataFrame, label: \u001b[38;5;28mstr\u001b[39m, problem_type: \u001b[38;5;28mstr\u001b[39m, test_size: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m, random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, min_cls_count_train: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    363\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (DataFrame, DataFrame):\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    Generate a train test split from a DataFrame that contains the label column.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m        The train_data and test_data after performing the split. Includes the label column.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mextract_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     train_data, test_data, y_train, y_test \u001b[38;5;241m=\u001b[39m generate_train_test_split(\n\u001b[1;32m    395\u001b[0m         X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, test_size\u001b[38;5;241m=\u001b[39mtest_size, random_state\u001b[38;5;241m=\u001b[39mrandom_state, min_cls_count_train\u001b[38;5;241m=\u001b[39mmin_cls_count_train\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    397\u001b[0m     train_data[label] \u001b[38;5;241m=\u001b[39m y_train\n",
      "File \u001b[0;32m~/Desktop/Work/autogluon/core/src/autogluon/core/utils/utils.py:355\u001b[0m, in \u001b[0;36mextract_label\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mExtract the label column from a dataset and return X, y.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    y is the label column as a pd.Series.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided DataFrame does not contain label column: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m y \u001b[38;5;241m=\u001b[39m data[label]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    357\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(label, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Provided DataFrame does not contain label column: ['education-num', 'education', 'class']"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235e829-9cb0-46fd-940b-18365e09de74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
